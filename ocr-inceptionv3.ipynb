{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13053123,"sourceType":"datasetVersion","datasetId":8265688}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================================================\n# Character Recognition with DenseNet121 (Transfer Learning, TF/Keras)\n# ====================================================\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import DenseNet121\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score\nfrom collections import defaultdict\n\n# -----------------------\n# CONFIG\n# -----------------------\ntrain_dir = \"/kaggle/input/ocr-data/OCR_data/train_data\"  \ntest_dir  = \"/kaggle/input/ocr-data/OCR_data/test_data\"   \nimg_size = (128, 128)\nbatch_size = 16\nepochs = 50 \n\n# -----------------------\n# CLASS MAPPING\n# -----------------------\ntrain_class_names = sorted({f[0] for f in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, f))})\nprint(\"Train classes (first letters):\", train_class_names)\n\nclass_to_index = {cls: idx for idx, cls in enumerate(train_class_names)}\nindex_to_class = {idx: cls for cls, idx in class_to_index.items()}\nnum_classes = len(class_to_index)\n\nprint(\"Class mapping:\", class_to_index)\nprint(\"Number of classes:\", num_classes)\n\n# -----------------------\n# DATASET LOADER\n# -----------------------\nkeys_tensor = tf.constant(list(class_to_index.keys()))\nvals_tensor = tf.constant(list(class_to_index.values()), dtype=tf.int32)\ntable = tf.lookup.StaticHashTable(\n    tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n    default_value=-1\n)\n\ndef process_path(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_png(img, channels=1)   # grayscale\n    img = tf.image.resize(img, img_size)\n    img = (tf.cast(img, tf.float32) / 127.5) - 1.0\n\n    parts = tf.strings.split(path, os.sep)\n    folder_name = parts[-2]\n    label_char = tf.strings.substr(folder_name, 0, 1)\n    label = table.lookup(label_char)\n\n    return img, label\n\ntrain_files = tf.data.Dataset.list_files(train_dir + \"/*/*\", shuffle=True)\ntest_files  = tf.data.Dataset.list_files(test_dir + \"/*/*\", shuffle=False)\n\nfull_train_ds = train_files.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Split into train/validation (80/20)\ntrain_size = int(0.8 * len(list(train_files)))\ntrain_ds = (full_train_ds.take(train_size)\n            .batch(batch_size)\n            .prefetch(tf.data.AUTOTUNE))\nval_ds = (full_train_ds.skip(train_size)\n          .batch(batch_size)\n          .prefetch(tf.data.AUTOTUNE))\n\ntest_ds = (test_files\n           .map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n           .batch(batch_size)\n           .prefetch(tf.data.AUTOTUNE))\n\n# -----------------------\n# MODEL: DenseNet121 Backbone\n# -----------------------\ndensenet_base = DenseNet121(\n    input_shape=(128,128,3),\n    include_top=False,\n    weights=\"imagenet\"\n)\n\ndensenet_base.trainable = False  # freeze backbone\n\ninputs = layers.Input(shape=(128,128,1))\nx = layers.Concatenate()([inputs, inputs, inputs])   # grayscale → RGB\nx = densenet_base(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(num_classes, activation=\"softmax\",\n                       kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n\nmodel = models.Model(inputs, outputs)\nmodel.summary()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-15T00:15:30.172936Z","iopub.execute_input":"2025-09-15T00:15:30.173583Z","iopub.status.idle":"2025-09-15T00:15:50.072695Z","shell.execute_reply.started":"2025-09-15T00:15:30.173559Z","shell.execute_reply":"2025-09-15T00:15:50.072063Z"}},"outputs":[{"name":"stderr","text":"2025-09-15 00:15:31.793654: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757895332.006805      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757895332.071861      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Train classes (first letters): ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\nClass mapping: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18, 'J': 19, 'K': 20, 'L': 21, 'M': 22, 'N': 23, 'O': 24, 'P': 25, 'Q': 26, 'R': 27, 'S': 28, 'T': 29, 'U': 30, 'V': 31, 'W': 32, 'X': 33, 'Y': 34, 'Z': 35, 'a': 36, 'b': 37, 'c': 38, 'd': 39, 'e': 40, 'f': 41, 'g': 42, 'h': 43, 'i': 44, 'j': 45, 'k': 46, 'l': 47, 'm': 48, 'n': 49, 'o': 50, 'p': 51, 'q': 52, 'r': 53, 's': 54, 't': 55, 'u': 56, 'v': 57, 'w': 58, 'x': 59, 'y': 60, 'z': 61}\nNumber of classes: 62\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1757895345.381204      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1757895345.381870      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m3\u001b[0m)                │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ densenet121         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m,      │  \u001b[38;5;34m7,037,504\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ densenet121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)        │     \u001b[38;5;34m63,550\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ densenet121         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ densenet121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">63,550</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,101,054\u001b[0m (27.09 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,101,054</span> (27.09 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,550\u001b[0m (248.24 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,550</span> (248.24 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n</pre>\n"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# -----------------------\n# COMPILE & TRAIN\n# -----------------------\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,\n    restore_best_weights=True\n)\n\nhistory = model.fit(\n    train_ds,\n    epochs=epochs,\n    validation_data=val_ds,\n    callbacks=[early_stop]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T00:15:50.073724Z","iopub.execute_input":"2025-09-15T00:15:50.073934Z","iopub.status.idle":"2025-09-15T00:17:37.349666Z","shell.execute_reply.started":"2025-09-15T00:15:50.073918Z","shell.execute_reply":"2025-09-15T00:17:37.349045Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757895367.674637      98 service.cc:148] XLA service 0x78bf44020820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757895367.675545      98 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757895367.675566      98 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757895370.317116      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 5/31\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0294 - loss: 6.0560     ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1757895379.012766      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.0212 - loss: 6.1916 - val_accuracy: 0.0968 - val_loss: 4.1036\nEpoch 2/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.0367 - loss: 5.1215 - val_accuracy: 0.1613 - val_loss: 3.4717\nEpoch 3/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.0950 - loss: 4.3214 - val_accuracy: 0.2419 - val_loss: 3.0022\nEpoch 4/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1110 - loss: 3.9156 - val_accuracy: 0.3790 - val_loss: 2.5539\nEpoch 5/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1835 - loss: 3.3372 - val_accuracy: 0.4274 - val_loss: 2.3720\nEpoch 6/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.1758 - loss: 3.0706 - val_accuracy: 0.5645 - val_loss: 2.0629\nEpoch 7/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2843 - loss: 2.7648 - val_accuracy: 0.6371 - val_loss: 1.7387\nEpoch 8/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3178 - loss: 2.5335 - val_accuracy: 0.7500 - val_loss: 1.5830\nEpoch 9/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2974 - loss: 2.4744 - val_accuracy: 0.7742 - val_loss: 1.4304\nEpoch 10/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4089 - loss: 2.2077 - val_accuracy: 0.7581 - val_loss: 1.3764\nEpoch 11/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4131 - loss: 2.0211 - val_accuracy: 0.8226 - val_loss: 1.1841\nEpoch 12/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4956 - loss: 1.8587 - val_accuracy: 0.8548 - val_loss: 1.0573\nEpoch 13/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5457 - loss: 1.6120 - val_accuracy: 0.9113 - val_loss: 0.9218\nEpoch 14/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5503 - loss: 1.5475 - val_accuracy: 0.9032 - val_loss: 0.9588\nEpoch 15/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5993 - loss: 1.4896 - val_accuracy: 0.8387 - val_loss: 0.9306\nEpoch 16/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5905 - loss: 1.4997 - val_accuracy: 0.8952 - val_loss: 0.7724\nEpoch 17/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6361 - loss: 1.2987 - val_accuracy: 0.9032 - val_loss: 0.7083\nEpoch 18/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6440 - loss: 1.2522 - val_accuracy: 0.9435 - val_loss: 0.6798\nEpoch 19/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6393 - loss: 1.2440 - val_accuracy: 0.9435 - val_loss: 0.5343\nEpoch 20/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6651 - loss: 1.1898 - val_accuracy: 0.9839 - val_loss: 0.5830\nEpoch 21/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6475 - loss: 1.2224 - val_accuracy: 0.9194 - val_loss: 0.6516\nEpoch 22/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6774 - loss: 1.1107 - val_accuracy: 0.9435 - val_loss: 0.5168\nEpoch 23/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6889 - loss: 1.0523 - val_accuracy: 0.9516 - val_loss: 0.5642\nEpoch 24/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7117 - loss: 1.0262 - val_accuracy: 0.9435 - val_loss: 0.5168\nEpoch 25/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8034 - loss: 0.8118 - val_accuracy: 0.9597 - val_loss: 0.4461\nEpoch 26/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8092 - loss: 0.8377 - val_accuracy: 0.9839 - val_loss: 0.4105\nEpoch 27/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8026 - loss: 0.7589 - val_accuracy: 0.9597 - val_loss: 0.4251\nEpoch 28/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7427 - loss: 0.8786 - val_accuracy: 0.9677 - val_loss: 0.4058\nEpoch 29/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8687 - loss: 0.6159 - val_accuracy: 0.9516 - val_loss: 0.3870\nEpoch 30/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8047 - loss: 0.7465 - val_accuracy: 0.9758 - val_loss: 0.3574\nEpoch 31/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8638 - loss: 0.6522 - val_accuracy: 0.9677 - val_loss: 0.3885\nEpoch 32/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8447 - loss: 0.6512 - val_accuracy: 0.9597 - val_loss: 0.3629\nEpoch 33/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8384 - loss: 0.6919 - val_accuracy: 0.9839 - val_loss: 0.3250\nEpoch 34/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8421 - loss: 0.6363 - val_accuracy: 0.9677 - val_loss: 0.2940\nEpoch 35/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8376 - loss: 0.6302 - val_accuracy: 0.9919 - val_loss: 0.2707\nEpoch 36/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8764 - loss: 0.5888 - val_accuracy: 0.9516 - val_loss: 0.3037\nEpoch 37/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8628 - loss: 0.5864 - val_accuracy: 0.9758 - val_loss: 0.2892\nEpoch 38/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8606 - loss: 0.5757 - val_accuracy: 0.9919 - val_loss: 0.2282\nEpoch 39/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8965 - loss: 0.4876 - val_accuracy: 0.9919 - val_loss: 0.2289\nEpoch 40/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8538 - loss: 0.5500 - val_accuracy: 0.9839 - val_loss: 0.2388\nEpoch 41/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8900 - loss: 0.5221 - val_accuracy: 0.9758 - val_loss: 0.1958\nEpoch 42/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8915 - loss: 0.5052 - val_accuracy: 0.9758 - val_loss: 0.2460\nEpoch 43/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8835 - loss: 0.5028 - val_accuracy: 0.9758 - val_loss: 0.2300\nEpoch 44/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9069 - loss: 0.4503 - val_accuracy: 0.9919 - val_loss: 0.2297\nEpoch 45/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9295 - loss: 0.4329 - val_accuracy: 1.0000 - val_loss: 0.2031\nEpoch 46/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9025 - loss: 0.4393 - val_accuracy: 0.9919 - val_loss: 0.2074\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# -----------------------\n# SAVE & LOAD\n# -----------------------\nmodel.save(\"densenet121_char_tf.h5\")\nprint(\"Model saved!\")\n\nloaded_model = tf.keras.models.load_model(\"densenet121_char_tf.h5\")\nprint(\"Model loaded!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T00:17:37.350797Z","iopub.execute_input":"2025-09-15T00:17:37.351017Z","iopub.status.idle":"2025-09-15T00:17:39.549035Z","shell.execute_reply.started":"2025-09-15T00:17:37.350999Z","shell.execute_reply":"2025-09-15T00:17:39.548345Z"}},"outputs":[{"name":"stdout","text":"Model saved!\nModel loaded!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# -----------------------\n# FINAL EVALUATION (TEST DATA)\n# -----------------------\ncorrect = 0\nwrong = 0\ntotal = 0\n\ny_true = []\ny_pred = []\nclass_correct = defaultdict(int)\nclass_total = defaultdict(int)\n\nfor images, labels in test_ds:\n    preds = loaded_model.predict(images, verbose=0)\n    predicted_classes = np.argmax(preds, axis=1)\n\n    y_true.extend(labels.numpy())\n    y_pred.extend(predicted_classes)\n\n    correct += np.sum(predicted_classes == labels.numpy())\n    wrong += np.sum(predicted_classes != labels.numpy())\n    total += labels.shape[0]\n\n    for true, pred in zip(labels.numpy(), predicted_classes):\n        class_total[true] += 1\n        if true == pred:\n            class_correct[true] += 1\n\nprint(\"\\n=== Per-Class Results ===\")\nfor idx in sorted(class_total.keys()):\n    total_i = class_total[idx]\n    correct_i = class_correct[idx]\n    wrong_i = total_i - correct_i\n    print(f\"Class {index_to_class[idx]}: Correct={correct_i}, Wrong={wrong_i}, Total={total_i}, Acc={100*correct_i/total_i:.2f}%\")\n\nprint(\"\\n=== Overall Results ===\")\nprint(f\"Correct predictions: {correct}\")\nprint(f\"Wrong predictions: {wrong}\")\nprint(f\"Total images: {total}\")\nprint(f\"Accuracy: {100.0 * correct / total:.2f}%\")\n\nprecision = precision_score(y_true, y_pred, average=\"macro\")\nrecall = recall_score(y_true, y_pred, average=\"macro\")\nf1 = f1_score(y_true, y_pred, average=\"macro\")\n\nprint(\"\\n=== Precision / Recall / F1 (Macro) ===\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall:    {recall:.4f}\")\nprint(f\"F1 Score:  {f1:.4f}\")\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_true, y_pred, target_names=[index_to_class[i] for i in range(num_classes)]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T00:17:39.550353Z","iopub.execute_input":"2025-09-15T00:17:39.550570Z","iopub.status.idle":"2025-09-15T00:18:10.763160Z","shell.execute_reply.started":"2025-09-15T00:17:39.550551Z","shell.execute_reply":"2025-09-15T00:18:10.762492Z"}},"outputs":[{"name":"stdout","text":"\n=== Per-Class Results ===\nClass 0: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass 1: Correct=3, Wrong=22, Total=25, Acc=12.00%\nClass 2: Correct=4, Wrong=21, Total=25, Acc=16.00%\nClass 3: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass 4: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass 5: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass 6: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass 7: Correct=2, Wrong=23, Total=25, Acc=8.00%\nClass 8: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass 9: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass A: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass B: Correct=20, Wrong=5, Total=25, Acc=80.00%\nClass C: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass D: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass E: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass F: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass G: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass H: Correct=20, Wrong=5, Total=25, Acc=80.00%\nClass I: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass J: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass K: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass L: Correct=24, Wrong=1, Total=25, Acc=96.00%\nClass M: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass N: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass O: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass P: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass Q: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass R: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass S: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass T: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass U: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass V: Correct=21, Wrong=4, Total=25, Acc=84.00%\nClass W: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass X: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass Y: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass Z: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass a: Correct=4, Wrong=21, Total=25, Acc=16.00%\nClass b: Correct=11, Wrong=14, Total=25, Acc=44.00%\nClass c: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass d: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass e: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass f: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass g: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass h: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass i: Correct=5, Wrong=20, Total=25, Acc=20.00%\nClass j: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass k: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass l: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass m: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass n: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass o: Correct=21, Wrong=4, Total=25, Acc=84.00%\nClass p: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass q: Correct=11, Wrong=14, Total=25, Acc=44.00%\nClass r: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass s: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass t: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass u: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass v: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass w: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass x: Correct=20, Wrong=5, Total=25, Acc=80.00%\nClass y: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass z: Correct=8, Wrong=17, Total=25, Acc=32.00%\n\n=== Overall Results ===\nCorrect predictions: 818\nWrong predictions: 732\nTotal images: 1550\nAccuracy: 52.77%\n\n=== Precision / Recall / F1 (Macro) ===\nPrecision: 0.5578\nRecall:    0.5277\nF1 Score:  0.5237\n\n=== Classification Report ===\n              precision    recall  f1-score   support\n\n           0       0.53      0.40      0.45        25\n           1       0.08      0.12      0.10        25\n           2       0.14      0.16      0.15        25\n           3       0.56      0.40      0.47        25\n           4       0.73      0.32      0.44        25\n           5       0.57      0.48      0.52        25\n           6       0.50      0.56      0.53        25\n           7       0.29      0.08      0.12        25\n           8       0.62      0.32      0.42        25\n           9       0.47      0.28      0.35        25\n           A       1.00      0.52      0.68        25\n           B       0.77      0.80      0.78        25\n           C       0.75      0.60      0.67        25\n           D       0.66      0.76      0.70        25\n           E       0.63      0.48      0.55        25\n           F       0.71      0.40      0.51        25\n           G       0.64      0.56      0.60        25\n           H       0.57      0.80      0.67        25\n           I       0.62      0.60      0.61        25\n           J       0.59      0.88      0.71        25\n           K       0.61      0.68      0.64        25\n           L       0.77      0.96      0.86        25\n           M       0.70      0.64      0.67        25\n           N       0.64      0.28      0.39        25\n           O       0.58      0.28      0.38        25\n           P       0.60      0.60      0.60        25\n           Q       0.70      0.76      0.73        25\n           R       0.52      0.56      0.54        25\n           S       0.73      0.64      0.68        25\n           T       0.95      0.72      0.82        25\n           U       0.45      0.56      0.50        25\n           V       0.62      0.84      0.71        25\n           W       0.63      0.48      0.55        25\n           X       0.81      0.68      0.74        25\n           Y       0.79      0.76      0.78        25\n           Z       0.46      0.76      0.58        25\n           a       0.24      0.16      0.19        25\n           b       0.41      0.44      0.42        25\n           c       0.55      0.72      0.62        25\n           d       0.43      0.40      0.42        25\n           e       0.82      0.56      0.67        25\n           f       0.41      0.28      0.33        25\n           g       0.86      0.24      0.38        25\n           h       0.41      0.28      0.33        25\n           i       0.29      0.20      0.24        25\n           j       0.52      0.52      0.52        25\n           k       0.32      0.56      0.41        25\n           l       0.22      0.24      0.23        25\n           m       0.71      0.68      0.69        25\n           n       0.57      0.64      0.60        25\n           o       0.45      0.84      0.58        25\n           p       0.58      0.60      0.59        25\n           q       0.22      0.44      0.29        25\n           r       0.63      0.68      0.65        25\n           s       0.53      0.76      0.62        25\n           t       0.44      0.68      0.53        25\n           u       0.29      0.56      0.38        25\n           v       0.83      0.76      0.79        25\n           w       0.40      0.24      0.30        25\n           x       0.83      0.80      0.82        25\n           y       0.27      0.40      0.32        25\n           z       0.40      0.32      0.36        25\n\n    accuracy                           0.53      1550\n   macro avg       0.56      0.53      0.52      1550\nweighted avg       0.56      0.53      0.52      1550\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}