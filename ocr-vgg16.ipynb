{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13053123,"sourceType":"datasetVersion","datasetId":8265688}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================================================\n# Character Recognition with VGG16 (Transfer Learning, TF/Keras)\n# ====================================================\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import VGG16\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score\nfrom collections import defaultdict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-14T22:40:11.830453Z","iopub.execute_input":"2025-09-14T22:40:11.830718Z","iopub.status.idle":"2025-09-14T22:40:29.341178Z","shell.execute_reply.started":"2025-09-14T22:40:11.830691Z","shell.execute_reply":"2025-09-14T22:40:29.340185Z"}},"outputs":[{"name":"stderr","text":"2025-09-14 22:40:13.625405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757889613.850009      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757889613.917730      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# -----------------------\n# CONFIG\n# -----------------------\ntrain_dir = \"/kaggle/input/ocr-data/OCR_data/train_data\"  \ntest_dir  = \"/kaggle/input/ocr-data/OCR_data/test_data\"   \nimg_size = (128, 128)\nbatch_size = 16\nepochs = 50 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T22:40:29.343142Z","iopub.execute_input":"2025-09-14T22:40:29.343816Z","iopub.status.idle":"2025-09-14T22:40:29.348417Z","shell.execute_reply.started":"2025-09-14T22:40:29.343787Z","shell.execute_reply":"2025-09-14T22:40:29.347544Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# -----------------------\n# CLASS MAPPING\n# -----------------------\ntrain_class_names = sorted({f[0] for f in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, f))})\nprint(\"Train classes (first letters):\", train_class_names)\n\nclass_to_index = {cls: idx for idx, cls in enumerate(train_class_names)}\nindex_to_class = {idx: cls for cls, idx in class_to_index.items()}\nnum_classes = len(class_to_index)\n\nprint(\"Class mapping:\", class_to_index)\nprint(\"Number of classes:\", num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T22:40:29.349361Z","iopub.execute_input":"2025-09-14T22:40:29.349708Z","iopub.status.idle":"2025-09-14T22:40:29.436528Z","shell.execute_reply.started":"2025-09-14T22:40:29.349679Z","shell.execute_reply":"2025-09-14T22:40:29.435685Z"}},"outputs":[{"name":"stdout","text":"Train classes (first letters): ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\nClass mapping: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18, 'J': 19, 'K': 20, 'L': 21, 'M': 22, 'N': 23, 'O': 24, 'P': 25, 'Q': 26, 'R': 27, 'S': 28, 'T': 29, 'U': 30, 'V': 31, 'W': 32, 'X': 33, 'Y': 34, 'Z': 35, 'a': 36, 'b': 37, 'c': 38, 'd': 39, 'e': 40, 'f': 41, 'g': 42, 'h': 43, 'i': 44, 'j': 45, 'k': 46, 'l': 47, 'm': 48, 'n': 49, 'o': 50, 'p': 51, 'q': 52, 'r': 53, 's': 54, 't': 55, 'u': 56, 'v': 57, 'w': 58, 'x': 59, 'y': 60, 'z': 61}\nNumber of classes: 62\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# -----------------------\n# DATASET LOADER\n# -----------------------\nkeys_tensor = tf.constant(list(class_to_index.keys()))\nvals_tensor = tf.constant(list(class_to_index.values()), dtype=tf.int32)\ntable = tf.lookup.StaticHashTable(\n    tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n    default_value=-1\n)\n\ndef process_path(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_png(img, channels=1)   # grayscale\n    img = tf.image.resize(img, img_size)\n    img = (tf.cast(img, tf.float32) / 127.5) - 1.0\n\n    parts = tf.strings.split(path, os.sep)\n    folder_name = parts[-2]\n    label_char = tf.strings.substr(folder_name, 0, 1)\n    label = table.lookup(label_char)\n\n    return img, label\n\ntrain_files = tf.data.Dataset.list_files(train_dir + \"/*/*\", shuffle=True)\ntest_files  = tf.data.Dataset.list_files(test_dir + \"/*/*\", shuffle=False)\n\nfull_train_ds = train_files.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Split into train/validation (80/20)\ntrain_size = int(0.8 * len(list(train_files)))\ntrain_ds = (full_train_ds.take(train_size)\n            .batch(batch_size)\n            .prefetch(tf.data.AUTOTUNE))\nval_ds = (full_train_ds.skip(train_size)\n          .batch(batch_size)\n          .prefetch(tf.data.AUTOTUNE))\n\ntest_ds = (test_files\n           .map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n           .batch(batch_size)\n           .prefetch(tf.data.AUTOTUNE))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T22:40:29.437585Z","iopub.execute_input":"2025-09-14T22:40:29.437927Z","iopub.status.idle":"2025-09-14T22:40:30.161614Z","shell.execute_reply.started":"2025-09-14T22:40:29.437898Z","shell.execute_reply":"2025-09-14T22:40:30.160707Z"}},"outputs":[{"name":"stderr","text":"2025-09-14 22:40:29.445878: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# -----------------------\n# MODEL: VGG16 Backbone\n# -----------------------\nvgg_base = VGG16(\n    input_shape=(128,128,3),\n    include_top=False,\n    weights=\"imagenet\"\n)\n\nvgg_base.trainable = False  # freeze backbone\n\ninputs = layers.Input(shape=(128,128,1))\nx = layers.Concatenate()([inputs, inputs, inputs])   # grayscale → RGB\nx = vgg_base(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(num_classes, activation=\"softmax\",\n                       kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n\nmodel = models.Model(inputs, outputs)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T22:40:30.162535Z","iopub.execute_input":"2025-09-14T22:40:30.162859Z","iopub.status.idle":"2025-09-14T22:40:32.898466Z","shell.execute_reply.started":"2025-09-14T22:40:30.162829Z","shell.execute_reply":"2025-09-14T22:40:32.897632Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m3\u001b[0m)                │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │ \u001b[38;5;34m14,714,688\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ vgg16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)        │     \u001b[38;5;34m31,806\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ vgg16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,806</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,746,494\u001b[0m (56.25 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,746,494</span> (56.25 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,806\u001b[0m (124.24 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,806</span> (124.24 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# -----------------------\n# COMPILE & TRAIN\n# -----------------------\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,\n    restore_best_weights=True\n)\n\nhistory = model.fit(\n    train_ds,\n    epochs=epochs,\n    validation_data=val_ds,\n    callbacks=[early_stop]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T22:40:32.899575Z","iopub.execute_input":"2025-09-14T22:40:32.900203Z","iopub.status.idle":"2025-09-14T23:20:44.515533Z","shell.execute_reply.started":"2025-09-14T22:40:32.900173Z","shell.execute_reply":"2025-09-14T23:20:44.514632Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.0163 - loss: 4.6712 - val_accuracy: 0.0242 - val_loss: 4.2586\nEpoch 2/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0278 - loss: 4.4170 - val_accuracy: 0.1048 - val_loss: 4.0453\nEpoch 3/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0277 - loss: 4.2237 - val_accuracy: 0.0968 - val_loss: 3.9379\nEpoch 4/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0267 - loss: 4.0367 - val_accuracy: 0.1855 - val_loss: 3.7855\nEpoch 5/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0838 - loss: 3.9409 - val_accuracy: 0.2339 - val_loss: 3.7323\nEpoch 6/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0800 - loss: 3.8316 - val_accuracy: 0.2823 - val_loss: 3.6462\nEpoch 7/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.0804 - loss: 3.7564 - val_accuracy: 0.3065 - val_loss: 3.5503\nEpoch 8/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.1309 - loss: 3.6178 - val_accuracy: 0.4194 - val_loss: 3.4346\nEpoch 9/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.1395 - loss: 3.6071 - val_accuracy: 0.4194 - val_loss: 3.4040\nEpoch 10/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.1771 - loss: 3.5207 - val_accuracy: 0.4839 - val_loss: 3.3164\nEpoch 11/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.1187 - loss: 3.4850 - val_accuracy: 0.6371 - val_loss: 3.2374\nEpoch 12/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.2199 - loss: 3.3788 - val_accuracy: 0.5161 - val_loss: 3.1896\nEpoch 13/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.2441 - loss: 3.2550 - val_accuracy: 0.5968 - val_loss: 3.1314\nEpoch 14/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.2758 - loss: 3.1483 - val_accuracy: 0.6613 - val_loss: 2.9601\nEpoch 15/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.2619 - loss: 3.1749 - val_accuracy: 0.7661 - val_loss: 2.9538\nEpoch 16/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.3186 - loss: 3.0362 - val_accuracy: 0.6694 - val_loss: 2.9126\nEpoch 17/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.3191 - loss: 3.0331 - val_accuracy: 0.7581 - val_loss: 2.9013\nEpoch 18/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.2969 - loss: 3.0470 - val_accuracy: 0.7500 - val_loss: 2.7999\nEpoch 19/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.4132 - loss: 2.9324 - val_accuracy: 0.7661 - val_loss: 2.7384\nEpoch 20/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.4361 - loss: 2.8576 - val_accuracy: 0.7823 - val_loss: 2.6778\nEpoch 21/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.4013 - loss: 2.8442 - val_accuracy: 0.8065 - val_loss: 2.6404\nEpoch 22/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.4398 - loss: 2.8069 - val_accuracy: 0.7661 - val_loss: 2.5853\nEpoch 23/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.4753 - loss: 2.6993 - val_accuracy: 0.7661 - val_loss: 2.5616\nEpoch 24/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.5053 - loss: 2.6686 - val_accuracy: 0.8387 - val_loss: 2.5207\nEpoch 25/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.5135 - loss: 2.6178 - val_accuracy: 0.7742 - val_loss: 2.5363\nEpoch 26/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.4777 - loss: 2.6990 - val_accuracy: 0.8065 - val_loss: 2.4507\nEpoch 27/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.5470 - loss: 2.5371 - val_accuracy: 0.8226 - val_loss: 2.4005\nEpoch 28/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.4989 - loss: 2.5316 - val_accuracy: 0.8952 - val_loss: 2.4094\nEpoch 29/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.5358 - loss: 2.5025 - val_accuracy: 0.7823 - val_loss: 2.3546\nEpoch 30/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6034 - loss: 2.4455 - val_accuracy: 0.8387 - val_loss: 2.3040\nEpoch 31/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5323 - loss: 2.4764 - val_accuracy: 0.8790 - val_loss: 2.2847\nEpoch 32/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6187 - loss: 2.3730 - val_accuracy: 0.8306 - val_loss: 2.2674\nEpoch 33/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.5641 - loss: 2.4291 - val_accuracy: 0.8065 - val_loss: 2.1946\nEpoch 34/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5847 - loss: 2.3260 - val_accuracy: 0.8629 - val_loss: 2.2131\nEpoch 35/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6048 - loss: 2.2447 - val_accuracy: 0.8468 - val_loss: 2.1823\nEpoch 36/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5960 - loss: 2.2969 - val_accuracy: 0.8790 - val_loss: 2.0720\nEpoch 37/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6186 - loss: 2.2710 - val_accuracy: 0.8952 - val_loss: 2.0863\nEpoch 38/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6875 - loss: 2.1220 - val_accuracy: 0.8226 - val_loss: 2.0547\nEpoch 39/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6675 - loss: 2.1853 - val_accuracy: 0.8710 - val_loss: 2.0822\nEpoch 40/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6925 - loss: 2.1352 - val_accuracy: 0.8629 - val_loss: 1.9871\nEpoch 41/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6182 - loss: 2.1742 - val_accuracy: 0.8871 - val_loss: 2.0093\nEpoch 42/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7079 - loss: 2.0401 - val_accuracy: 0.8548 - val_loss: 1.8829\nEpoch 43/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6900 - loss: 2.0510 - val_accuracy: 0.8468 - val_loss: 1.9980\nEpoch 44/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7040 - loss: 2.0377 - val_accuracy: 0.8871 - val_loss: 1.9286\nEpoch 45/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7026 - loss: 2.0194 - val_accuracy: 0.8548 - val_loss: 1.8523\nEpoch 46/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6916 - loss: 1.9975 - val_accuracy: 0.8468 - val_loss: 1.9202\nEpoch 47/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7052 - loss: 2.0029 - val_accuracy: 0.9194 - val_loss: 1.7467\nEpoch 48/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.6909 - loss: 2.0467 - val_accuracy: 0.9032 - val_loss: 1.7426\nEpoch 49/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7198 - loss: 1.9144 - val_accuracy: 0.8952 - val_loss: 1.8417\nEpoch 50/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.7438 - loss: 1.9554 - val_accuracy: 0.9194 - val_loss: 1.7444\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# -----------------------\n# SAVE & LOAD\n# -----------------------\nmodel.save(\"vgg16_char_tf.h5\")\nprint(\"Model saved!\")\n\nloaded_model = tf.keras.models.load_model(\"vgg16_char_tf.h5\")\nprint(\"Model loaded!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T23:20:44.518192Z","iopub.execute_input":"2025-09-14T23:20:44.518464Z","iopub.status.idle":"2025-09-14T23:20:44.878144Z","shell.execute_reply.started":"2025-09-14T23:20:44.518442Z","shell.execute_reply":"2025-09-14T23:20:44.876992Z"}},"outputs":[{"name":"stdout","text":"Model saved!\nModel loaded!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# -----------------------\n# FINAL EVALUATION (TEST DATA)\n# -----------------------\ncorrect = 0\nwrong = 0\ntotal = 0\n\ny_true = []\ny_pred = []\nclass_correct = defaultdict(int)\nclass_total = defaultdict(int)\n\nfor images, labels in test_ds:\n    preds = loaded_model.predict(images, verbose=0)\n    predicted_classes = np.argmax(preds, axis=1)\n\n    y_true.extend(labels.numpy())\n    y_pred.extend(predicted_classes)\n\n    correct += np.sum(predicted_classes == labels.numpy())\n    wrong += np.sum(predicted_classes != labels.numpy())\n    total += labels.shape[0]\n\n    for true, pred in zip(labels.numpy(), predicted_classes):\n        class_total[true] += 1\n        if true == pred:\n            class_correct[true] += 1\n\nprint(\"\\n=== Per-Class Results ===\")\nfor idx in sorted(class_total.keys()):\n    total_i = class_total[idx]\n    correct_i = class_correct[idx]\n    wrong_i = total_i - correct_i\n    print(f\"Class {index_to_class[idx]}: Correct={correct_i}, Wrong={wrong_i}, Total={total_i}, Acc={100*correct_i/total_i:.2f}%\")\n\nprint(\"\\n=== Overall Results ===\")\nprint(f\"Correct predictions: {correct}\")\nprint(f\"Wrong predictions: {wrong}\")\nprint(f\"Total images: {total}\")\nprint(f\"Accuracy: {100.0 * correct / total:.2f}%\")\n\nprecision = precision_score(y_true, y_pred, average=\"macro\")\nrecall = recall_score(y_true, y_pred, average=\"macro\")\nf1 = f1_score(y_true, y_pred, average=\"macro\")\n\nprint(\"\\n=== Precision / Recall / F1 (Macro) ===\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall:    {recall:.4f}\")\nprint(f\"F1 Score:  {f1:.4f}\")\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_true, y_pred, target_names=[index_to_class[i] for i in range(num_classes)]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T23:20:44.879166Z","iopub.execute_input":"2025-09-14T23:20:44.879520Z","iopub.status.idle":"2025-09-14T23:23:00.247874Z","shell.execute_reply.started":"2025-09-14T23:20:44.879488Z","shell.execute_reply":"2025-09-14T23:23:00.246884Z"}},"outputs":[{"name":"stdout","text":"\n=== Per-Class Results ===\nClass 0: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass 1: Correct=1, Wrong=24, Total=25, Acc=4.00%\nClass 2: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass 3: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass 4: Correct=9, Wrong=16, Total=25, Acc=36.00%\nClass 5: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass 6: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass 7: Correct=4, Wrong=21, Total=25, Acc=16.00%\nClass 8: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass 9: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass A: Correct=11, Wrong=14, Total=25, Acc=44.00%\nClass B: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass C: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass D: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass E: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass F: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass G: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass H: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass I: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass J: Correct=20, Wrong=5, Total=25, Acc=80.00%\nClass K: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass L: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass M: Correct=11, Wrong=14, Total=25, Acc=44.00%\nClass N: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass O: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass P: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass Q: Correct=21, Wrong=4, Total=25, Acc=84.00%\nClass R: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass S: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass T: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass U: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass V: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass W: Correct=11, Wrong=14, Total=25, Acc=44.00%\nClass X: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass Y: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass Z: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass a: Correct=2, Wrong=23, Total=25, Acc=8.00%\nClass b: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass c: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass d: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass e: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass f: Correct=9, Wrong=16, Total=25, Acc=36.00%\nClass g: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass h: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass i: Correct=4, Wrong=21, Total=25, Acc=16.00%\nClass j: Correct=9, Wrong=16, Total=25, Acc=36.00%\nClass k: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass l: Correct=5, Wrong=20, Total=25, Acc=20.00%\nClass m: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass n: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass o: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass p: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass q: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass r: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass s: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass t: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass u: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass v: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass w: Correct=11, Wrong=14, Total=25, Acc=44.00%\nClass x: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass y: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass z: Correct=6, Wrong=19, Total=25, Acc=24.00%\n\n=== Overall Results ===\nCorrect predictions: 731\nWrong predictions: 819\nTotal images: 1550\nAccuracy: 47.16%\n\n=== Precision / Recall / F1 (Macro) ===\nPrecision: 0.5266\nRecall:    0.4716\nF1 Score:  0.4645\n\n=== Classification Report ===\n              precision    recall  f1-score   support\n\n           0       0.47      0.28      0.35        25\n           1       0.12      0.04      0.06        25\n           2       0.42      0.32      0.36        25\n           3       0.45      0.60      0.52        25\n           4       0.82      0.36      0.50        25\n           5       0.83      0.40      0.54        25\n           6       0.25      0.60      0.35        25\n           7       0.27      0.16      0.20        25\n           8       0.56      0.40      0.47        25\n           9       0.67      0.32      0.43        25\n           A       0.46      0.44      0.45        25\n           B       0.86      0.48      0.62        25\n           C       0.60      0.72      0.65        25\n           D       0.89      0.64      0.74        25\n           E       0.80      0.32      0.46        25\n           F       0.59      0.52      0.55        25\n           G       0.53      0.40      0.45        25\n           H       0.56      0.40      0.47        25\n           I       0.64      0.28      0.39        25\n           J       0.74      0.80      0.77        25\n           K       0.67      0.64      0.65        25\n           L       0.61      0.88      0.72        25\n           M       0.28      0.44      0.34        25\n           N       0.73      0.32      0.44        25\n           O       0.57      0.32      0.41        25\n           P       0.56      0.56      0.56        25\n           Q       0.64      0.84      0.72        25\n           R       0.57      0.32      0.41        25\n           S       0.55      0.48      0.51        25\n           T       0.68      0.76      0.72        25\n           U       0.37      0.40      0.38        25\n           V       0.53      0.64      0.58        25\n           W       0.85      0.44      0.58        25\n           X       0.55      0.88      0.68        25\n           Y       0.89      0.64      0.74        25\n           Z       0.46      0.88      0.60        25\n           a       0.22      0.08      0.12        25\n           b       0.36      0.32      0.34        25\n           c       0.60      0.72      0.65        25\n           d       0.67      0.24      0.35        25\n           e       0.56      0.40      0.47        25\n           f       0.29      0.36      0.32        25\n           g       0.41      0.48      0.44        25\n           h       0.29      0.24      0.26        25\n           i       0.29      0.16      0.21        25\n           j       0.38      0.36      0.37        25\n           k       0.32      0.32      0.32        25\n           l       0.12      0.20      0.15        25\n           m       1.00      0.48      0.65        25\n           n       0.47      0.76      0.58        25\n           o       0.30      0.88      0.45        25\n           p       0.63      0.48      0.55        25\n           q       0.43      0.24      0.31        25\n           r       0.46      0.64      0.53        25\n           s       0.39      0.76      0.51        25\n           t       0.22      0.32      0.26        25\n           u       0.42      0.52      0.46        25\n           v       0.48      0.56      0.52        25\n           w       0.31      0.44      0.37        25\n           x       0.31      0.88      0.46        25\n           y       0.86      0.24      0.38        25\n           z       0.86      0.24      0.38        25\n\n    accuracy                           0.47      1550\n   macro avg       0.53      0.47      0.46      1550\nweighted avg       0.53      0.47      0.46      1550\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}