{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13053123,"sourceType":"datasetVersion","datasetId":8265688}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================================================\n# Character Recognition with DenseNet121 (Transfer Learning, TF/Keras)\n# ====================================================\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import DenseNet121\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score\nfrom collections import defaultdict\n\n# -----------------------\n# CONFIG\n# -----------------------\ntrain_dir = \"/kaggle/input/ocr-data/OCR_data/train_data\"  \ntest_dir  = \"/kaggle/input/ocr-data/OCR_data/test_data\"   \nimg_size = (128, 128)\nbatch_size = 16\nepochs = 50 \n\n# -----------------------\n# CLASS MAPPING\n# -----------------------\ntrain_class_names = sorted({f[0] for f in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, f))})\nprint(\"Train classes (first letters):\", train_class_names)\n\nclass_to_index = {cls: idx for idx, cls in enumerate(train_class_names)}\nindex_to_class = {idx: cls for cls, idx in class_to_index.items()}\nnum_classes = len(class_to_index)\n\nprint(\"Class mapping:\", class_to_index)\nprint(\"Number of classes:\", num_classes)\n\n# -----------------------\n# DATASET LOADER\n# -----------------------\nkeys_tensor = tf.constant(list(class_to_index.keys()))\nvals_tensor = tf.constant(list(class_to_index.values()), dtype=tf.int32)\ntable = tf.lookup.StaticHashTable(\n    tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n    default_value=-1\n)\n\ndef process_path(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_png(img, channels=1)   # grayscale\n    img = tf.image.resize(img, img_size)\n    img = (tf.cast(img, tf.float32) / 127.5) - 1.0\n\n    parts = tf.strings.split(path, os.sep)\n    folder_name = parts[-2]\n    label_char = tf.strings.substr(folder_name, 0, 1)\n    label = table.lookup(label_char)\n\n    return img, label\n\ntrain_files = tf.data.Dataset.list_files(train_dir + \"/*/*\", shuffle=True)\ntest_files  = tf.data.Dataset.list_files(test_dir + \"/*/*\", shuffle=False)\n\nfull_train_ds = train_files.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Split into train/validation (80/20)\ntrain_size = int(0.8 * len(list(train_files)))\ntrain_ds = (full_train_ds.take(train_size)\n            .batch(batch_size)\n            .prefetch(tf.data.AUTOTUNE))\nval_ds = (full_train_ds.skip(train_size)\n          .batch(batch_size)\n          .prefetch(tf.data.AUTOTUNE))\n\ntest_ds = (test_files\n           .map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n           .batch(batch_size)\n           .prefetch(tf.data.AUTOTUNE))\n\n# -----------------------\n# MODEL: DenseNet121 Backbone\n# -----------------------\ndensenet_base = DenseNet121(\n    input_shape=(128,128,3),\n    include_top=False,\n    weights=\"imagenet\"\n)\n\ndensenet_base.trainable = False  # freeze backbone\n\ninputs = layers.Input(shape=(128,128,1))\nx = layers.Concatenate()([inputs, inputs, inputs])   # grayscale → RGB\nx = densenet_base(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(num_classes, activation=\"softmax\",\n                       kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n\nmodel = models.Model(inputs, outputs)\nmodel.summary()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-14T23:45:13.044692Z","iopub.execute_input":"2025-09-14T23:45:13.045194Z","iopub.status.idle":"2025-09-14T23:45:15.147735Z","shell.execute_reply.started":"2025-09-14T23:45:13.045168Z","shell.execute_reply":"2025-09-14T23:45:15.147078Z"}},"outputs":[{"name":"stdout","text":"Train classes (first letters): ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\nClass mapping: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, 'A': 10, 'B': 11, 'C': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18, 'J': 19, 'K': 20, 'L': 21, 'M': 22, 'N': 23, 'O': 24, 'P': 25, 'Q': 26, 'R': 27, 'S': 28, 'T': 29, 'U': 30, 'V': 31, 'W': 32, 'X': 33, 'Y': 34, 'Z': 35, 'a': 36, 'b': 37, 'c': 38, 'd': 39, 'e': 40, 'f': 41, 'g': 42, 'h': 43, 'i': 44, 'j': 45, 'k': 46, 'l': 47, 'm': 48, 'n': 49, 'o': 50, 'p': 51, 'q': 52, 'r': 53, 's': 54, 't': 55, 'u': 56, 'v': 57, 'w': 58, 'x': 59, 'y': 60, 'z': 61}\nNumber of classes: 62\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m3\u001b[0m)                │            │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ densenet121         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m,      │  \u001b[38;5;34m7,037,504\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ densenet121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)        │     \u001b[38;5;34m63,550\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ densenet121         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ densenet121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">63,550</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,101,054\u001b[0m (27.09 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,101,054</span> (27.09 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,550\u001b[0m (248.24 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,550</span> (248.24 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n</pre>\n"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# -----------------------\n# COMPILE & TRAIN\n# -----------------------\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=5,\n    restore_best_weights=True\n)\n\nhistory = model.fit(\n    train_ds,\n    epochs=epochs,\n    validation_data=val_ds,\n    callbacks=[early_stop]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T23:45:19.583371Z","iopub.execute_input":"2025-09-14T23:45:19.584066Z","iopub.status.idle":"2025-09-14T23:47:09.019940Z","shell.execute_reply.started":"2025-09-14T23:45:19.584042Z","shell.execute_reply":"2025-09-14T23:47:09.019357Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757893537.152799      95 service.cc:148] XLA service 0x7bcdf8003cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757893537.153713      95 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757893537.153737      95 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1757893539.843002      95 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 5/31\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0431 - loss: 6.6983     ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1757893548.530899      95 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - accuracy: 0.0392 - loss: 6.2414 - val_accuracy: 0.0323 - val_loss: 4.0166\nEpoch 2/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0441 - loss: 5.1555 - val_accuracy: 0.1290 - val_loss: 3.5147\nEpoch 3/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.0562 - loss: 4.3108 - val_accuracy: 0.2177 - val_loss: 3.0556\nEpoch 4/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.1111 - loss: 3.9372 - val_accuracy: 0.4435 - val_loss: 2.5163\nEpoch 5/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.1871 - loss: 3.3667 - val_accuracy: 0.4677 - val_loss: 2.3179\nEpoch 6/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.2043 - loss: 3.1079 - val_accuracy: 0.5887 - val_loss: 1.8784\nEpoch 7/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2418 - loss: 2.9412 - val_accuracy: 0.7500 - val_loss: 1.6847\nEpoch 8/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3255 - loss: 2.4298 - val_accuracy: 0.7419 - val_loss: 1.5241\nEpoch 9/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3828 - loss: 2.3437 - val_accuracy: 0.7581 - val_loss: 1.4803\nEpoch 10/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3758 - loss: 2.2178 - val_accuracy: 0.8468 - val_loss: 1.2467\nEpoch 11/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4569 - loss: 1.8668 - val_accuracy: 0.7419 - val_loss: 1.2960\nEpoch 12/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4224 - loss: 1.9556 - val_accuracy: 0.8952 - val_loss: 0.9885\nEpoch 13/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5012 - loss: 1.7235 - val_accuracy: 0.8468 - val_loss: 1.0556\nEpoch 14/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5380 - loss: 1.6878 - val_accuracy: 0.9032 - val_loss: 0.7645\nEpoch 15/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5997 - loss: 1.4776 - val_accuracy: 0.8952 - val_loss: 0.9190\nEpoch 16/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5621 - loss: 1.5105 - val_accuracy: 0.9113 - val_loss: 0.7634\nEpoch 17/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6274 - loss: 1.2686 - val_accuracy: 0.9032 - val_loss: 0.7716\nEpoch 18/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6421 - loss: 1.2841 - val_accuracy: 0.9355 - val_loss: 0.6164\nEpoch 19/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6913 - loss: 1.0784 - val_accuracy: 0.9194 - val_loss: 0.6154\nEpoch 20/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6852 - loss: 1.1827 - val_accuracy: 0.9274 - val_loss: 0.6752\nEpoch 21/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6696 - loss: 1.1638 - val_accuracy: 0.9597 - val_loss: 0.5330\nEpoch 22/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7394 - loss: 1.0149 - val_accuracy: 0.9274 - val_loss: 0.5773\nEpoch 23/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7569 - loss: 0.9709 - val_accuracy: 0.9435 - val_loss: 0.5395\nEpoch 24/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7730 - loss: 0.9387 - val_accuracy: 0.9758 - val_loss: 0.4126\nEpoch 25/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7942 - loss: 0.8354 - val_accuracy: 0.9758 - val_loss: 0.4385\nEpoch 26/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7553 - loss: 0.8907 - val_accuracy: 0.9597 - val_loss: 0.4703\nEpoch 27/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7798 - loss: 0.8427 - val_accuracy: 0.9355 - val_loss: 0.4184\nEpoch 28/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8281 - loss: 0.6875 - val_accuracy: 0.9355 - val_loss: 0.4702\nEpoch 29/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8559 - loss: 0.6916 - val_accuracy: 0.9758 - val_loss: 0.4104\nEpoch 30/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7947 - loss: 0.7528 - val_accuracy: 0.9677 - val_loss: 0.3386\nEpoch 31/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8296 - loss: 0.7472 - val_accuracy: 0.9919 - val_loss: 0.3606\nEpoch 32/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8615 - loss: 0.6524 - val_accuracy: 0.9758 - val_loss: 0.3478\nEpoch 33/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8475 - loss: 0.6614 - val_accuracy: 0.9597 - val_loss: 0.3269\nEpoch 34/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8549 - loss: 0.6621 - val_accuracy: 0.9758 - val_loss: 0.3343\nEpoch 35/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8625 - loss: 0.5702 - val_accuracy: 0.9839 - val_loss: 0.3003\nEpoch 36/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8789 - loss: 0.5771 - val_accuracy: 0.9758 - val_loss: 0.2971\nEpoch 37/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8568 - loss: 0.6108 - val_accuracy: 0.9919 - val_loss: 0.2614\nEpoch 38/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8684 - loss: 0.5474 - val_accuracy: 1.0000 - val_loss: 0.2695\nEpoch 39/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8978 - loss: 0.4750 - val_accuracy: 0.9677 - val_loss: 0.2848\nEpoch 40/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8926 - loss: 0.5053 - val_accuracy: 0.9919 - val_loss: 0.2779\nEpoch 41/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8890 - loss: 0.5065 - val_accuracy: 1.0000 - val_loss: 0.1770\nEpoch 42/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9117 - loss: 0.4380 - val_accuracy: 0.9919 - val_loss: 0.1999\nEpoch 43/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8698 - loss: 0.4976 - val_accuracy: 1.0000 - val_loss: 0.1705\nEpoch 44/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8911 - loss: 0.5207 - val_accuracy: 0.9839 - val_loss: 0.2110\nEpoch 45/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8933 - loss: 0.4734 - val_accuracy: 0.9839 - val_loss: 0.2182\nEpoch 46/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9150 - loss: 0.4198 - val_accuracy: 0.9839 - val_loss: 0.2150\nEpoch 47/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9299 - loss: 0.4287 - val_accuracy: 0.9919 - val_loss: 0.1810\nEpoch 48/50\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9261 - loss: 0.3905 - val_accuracy: 0.9919 - val_loss: 0.2030\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# -----------------------\n# SAVE & LOAD\n# -----------------------\nmodel.save(\"densenet121_char_tf.h5\")\nprint(\"Model saved!\")\n\nloaded_model = tf.keras.models.load_model(\"densenet121_char_tf.h5\")\nprint(\"Model loaded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T23:47:09.021507Z","iopub.execute_input":"2025-09-14T23:47:09.021726Z","iopub.status.idle":"2025-09-14T23:47:11.640037Z","shell.execute_reply.started":"2025-09-14T23:47:09.021706Z","shell.execute_reply":"2025-09-14T23:47:11.639281Z"}},"outputs":[{"name":"stdout","text":"Model saved!\nModel loaded!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# -----------------------\n# FINAL EVALUATION (TEST DATA)\n# -----------------------\ncorrect = 0\nwrong = 0\ntotal = 0\n\ny_true = []\ny_pred = []\nclass_correct = defaultdict(int)\nclass_total = defaultdict(int)\n\nfor images, labels in test_ds:\n    preds = loaded_model.predict(images, verbose=0)\n    predicted_classes = np.argmax(preds, axis=1)\n\n    y_true.extend(labels.numpy())\n    y_pred.extend(predicted_classes)\n\n    correct += np.sum(predicted_classes == labels.numpy())\n    wrong += np.sum(predicted_classes != labels.numpy())\n    total += labels.shape[0]\n\n    for true, pred in zip(labels.numpy(), predicted_classes):\n        class_total[true] += 1\n        if true == pred:\n            class_correct[true] += 1\n\nprint(\"\\n=== Per-Class Results ===\")\nfor idx in sorted(class_total.keys()):\n    total_i = class_total[idx]\n    correct_i = class_correct[idx]\n    wrong_i = total_i - correct_i\n    print(f\"Class {index_to_class[idx]}: Correct={correct_i}, Wrong={wrong_i}, Total={total_i}, Acc={100*correct_i/total_i:.2f}%\")\n\nprint(\"\\n=== Overall Results ===\")\nprint(f\"Correct predictions: {correct}\")\nprint(f\"Wrong predictions: {wrong}\")\nprint(f\"Total images: {total}\")\nprint(f\"Accuracy: {100.0 * correct / total:.2f}%\")\n\nprecision = precision_score(y_true, y_pred, average=\"macro\")\nrecall = recall_score(y_true, y_pred, average=\"macro\")\nf1 = f1_score(y_true, y_pred, average=\"macro\")\n\nprint(\"\\n=== Precision / Recall / F1 (Macro) ===\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall:    {recall:.4f}\")\nprint(f\"F1 Score:  {f1:.4f}\")\n\nprint(\"\\n=== Classification Report ===\")\nprint(classification_report(y_true, y_pred, target_names=[index_to_class[i] for i in range(num_classes)]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T23:47:11.640839Z","iopub.execute_input":"2025-09-14T23:47:11.641170Z","iopub.status.idle":"2025-09-14T23:47:43.053704Z","shell.execute_reply.started":"2025-09-14T23:47:11.641147Z","shell.execute_reply":"2025-09-14T23:47:43.053068Z"}},"outputs":[{"name":"stdout","text":"\n=== Per-Class Results ===\nClass 0: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass 1: Correct=3, Wrong=22, Total=25, Acc=12.00%\nClass 2: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass 3: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass 4: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass 5: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass 6: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass 7: Correct=2, Wrong=23, Total=25, Acc=8.00%\nClass 8: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass 9: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass A: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass B: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass C: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass D: Correct=20, Wrong=5, Total=25, Acc=80.00%\nClass E: Correct=9, Wrong=16, Total=25, Acc=36.00%\nClass F: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass G: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass H: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass I: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass J: Correct=21, Wrong=4, Total=25, Acc=84.00%\nClass K: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass L: Correct=23, Wrong=2, Total=25, Acc=92.00%\nClass M: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass N: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass O: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass P: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass Q: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass R: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass S: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass T: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass U: Correct=18, Wrong=7, Total=25, Acc=72.00%\nClass V: Correct=22, Wrong=3, Total=25, Acc=88.00%\nClass W: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass X: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass Y: Correct=20, Wrong=5, Total=25, Acc=80.00%\nClass Z: Correct=21, Wrong=4, Total=25, Acc=84.00%\nClass a: Correct=3, Wrong=22, Total=25, Acc=12.00%\nClass b: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass c: Correct=19, Wrong=6, Total=25, Acc=76.00%\nClass d: Correct=9, Wrong=16, Total=25, Acc=36.00%\nClass e: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass f: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass g: Correct=8, Wrong=17, Total=25, Acc=32.00%\nClass h: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass i: Correct=4, Wrong=21, Total=25, Acc=16.00%\nClass j: Correct=9, Wrong=16, Total=25, Acc=36.00%\nClass k: Correct=11, Wrong=14, Total=25, Acc=44.00%\nClass l: Correct=7, Wrong=18, Total=25, Acc=28.00%\nClass m: Correct=14, Wrong=11, Total=25, Acc=56.00%\nClass n: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass o: Correct=21, Wrong=4, Total=25, Acc=84.00%\nClass p: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass q: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass r: Correct=10, Wrong=15, Total=25, Acc=40.00%\nClass s: Correct=16, Wrong=9, Total=25, Acc=64.00%\nClass t: Correct=17, Wrong=8, Total=25, Acc=68.00%\nClass u: Correct=13, Wrong=12, Total=25, Acc=52.00%\nClass v: Correct=15, Wrong=10, Total=25, Acc=60.00%\nClass w: Correct=6, Wrong=19, Total=25, Acc=24.00%\nClass x: Correct=21, Wrong=4, Total=25, Acc=84.00%\nClass y: Correct=12, Wrong=13, Total=25, Acc=48.00%\nClass z: Correct=7, Wrong=18, Total=25, Acc=28.00%\n\n=== Overall Results ===\nCorrect predictions: 805\nWrong predictions: 745\nTotal images: 1550\nAccuracy: 51.94%\n\n=== Precision / Recall / F1 (Macro) ===\nPrecision: 0.5487\nRecall:    0.5194\nF1 Score:  0.5147\n\n=== Classification Report ===\n              precision    recall  f1-score   support\n\n           0       0.48      0.40      0.43        25\n           1       0.10      0.12      0.11        25\n           2       0.19      0.24      0.21        25\n           3       0.59      0.68      0.63        25\n           4       0.67      0.32      0.43        25\n           5       0.67      0.40      0.50        25\n           6       0.42      0.52      0.46        25\n           7       0.25      0.08      0.12        25\n           8       0.53      0.32      0.40        25\n           9       0.46      0.24      0.32        25\n           A       0.87      0.52      0.65        25\n           B       0.81      0.88      0.85        25\n           C       0.70      0.64      0.67        25\n           D       0.77      0.80      0.78        25\n           E       0.64      0.36      0.46        25\n           F       0.53      0.40      0.45        25\n           G       0.63      0.48      0.55        25\n           H       0.61      0.76      0.68        25\n           I       0.71      0.60      0.65        25\n           J       0.75      0.84      0.79        25\n           K       0.59      0.76      0.67        25\n           L       0.72      0.92      0.81        25\n           M       0.62      0.72      0.67        25\n           N       0.50      0.24      0.32        25\n           O       0.46      0.24      0.32        25\n           P       0.38      0.40      0.39        25\n           Q       0.69      0.72      0.71        25\n           R       0.45      0.60      0.52        25\n           S       0.79      0.60      0.68        25\n           T       0.82      0.72      0.77        25\n           U       0.49      0.72      0.58        25\n           V       0.56      0.88      0.69        25\n           W       0.87      0.52      0.65        25\n           X       0.86      0.76      0.81        25\n           Y       0.65      0.80      0.71        25\n           Z       0.54      0.84      0.66        25\n           a       0.20      0.12      0.15        25\n           b       0.46      0.52      0.49        25\n           c       0.44      0.76      0.56        25\n           d       0.64      0.36      0.46        25\n           e       0.71      0.60      0.65        25\n           f       0.32      0.28      0.30        25\n           g       0.73      0.32      0.44        25\n           h       0.25      0.28      0.26        25\n           i       0.20      0.16      0.18        25\n           j       0.45      0.36      0.40        25\n           k       0.24      0.44      0.31        25\n           l       0.19      0.28      0.23        25\n           m       0.67      0.56      0.61        25\n           n       0.53      0.68      0.60        25\n           o       0.48      0.84      0.61        25\n           p       0.43      0.52      0.47        25\n           q       0.31      0.40      0.35        25\n           r       0.83      0.40      0.54        25\n           s       0.62      0.64      0.63        25\n           t       0.45      0.68      0.54        25\n           u       0.39      0.52      0.45        25\n           v       0.88      0.60      0.71        25\n           w       0.46      0.24      0.32        25\n           x       0.95      0.84      0.89        25\n           y       0.20      0.48      0.28        25\n           z       0.58      0.28      0.38        25\n\n    accuracy                           0.52      1550\n   macro avg       0.55      0.52      0.51      1550\nweighted avg       0.55      0.52      0.51      1550\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}